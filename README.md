# Hand Gesture Recognition with Hand Landmarks Using MediaPipe

## ğŸ“ Project Description

This project focuses on developing a **Hand Gesture Recognition** system using **MediaPipe**, a framework by Google for building machine learning pipelines. The goal is to enable real-time recognition of hand gestures, which can be used to improve human-computer interaction, especially for individuals with hearing impairments.

The system recognizes four basic hand gestures: **Open**, **Close**, **Pointer**, and **OK**. It uses **MediaPipe's Hand Landmark Model** to detect and track 21 key points on the hand, which are then used to classify the gestures in real-time.

## ğŸš€ Key Features

- **Real-Time Hand Gesture Recognition**: Detects and classifies hand gestures in real-time using a webcam.
- **Four Gesture Classes**: Recognizes **Open**, **Close**, **Pointer**, and **OK** gestures.
- **High Accuracy**: Achieves **97% accuracy** in gesture classification.
- **Easy to Use**: Simple interface for real-time testing and demonstration.

## ğŸ› ï¸ Technologies Used

- **MediaPipe**: Framework for hand landmark detection and gesture recognition.
- **OpenCV**: Library for real-time image processing and webcam integration.
- **TensorFlow**: Used for building and training the machine learning model.
- **Python**: Programming language used for development.
- **Scikit-learn**: Library for model evaluation and performance metrics.

## ğŸ“‚ Repository Structure

```
HandGestureRecognition
â”œâ”€â”€ /code # Python code for real-time gesture recognition
â”œâ”€â”€ /reference # reference paper
â”œâ”€â”€ paper # paper of this project
â”œâ”€â”€ README.md # This README file
```

## ğŸ“ Contact

Muhammad Aidan Daffa Junaidi - muhammad.aidan@ui.ac.id

GitHub: aidandf29
